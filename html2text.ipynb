{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HTML Information Extraction Toolkit**\n",
    "#### Introduction\n",
    "\n",
    "This notebook demonstrates how to preprocess HTML pages and extract useful textual information. It uses two Python libraries: \n",
    "- `trafilatura` for general-purpose text extraction.\n",
    "- `news-please` for structured information extraction, especially for news articles.\n",
    "\n",
    "We will walk through the process step-by-step, extracting clean and meaningful text from raw HTML files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Required Libraries**\n",
    "Make sure you have the necessary libraries installed. If not, run the following command in your terminal or notebook:\n",
    "\n",
    "```bash\n",
    "!pip install trafilatura news-please\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Import Necessary Libraries**\n",
    "\n",
    "Here, we import the required libraries to handle file operations, multiprocessing for efficiency, and text extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import multiprocessing\n",
    "import re\n",
    "import trafilatura\n",
    "from newsplease import NewsPlease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Set the Directory Path**\n",
    "\n",
    "\n",
    "Define the base directory where all your HTML files are stored. Make sure you have a folder named `html` containing the files you want to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URI = 'html/'  # Update this path if your folder is elsewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Create a Function to Clean Text**\n",
    "\n",
    "\n",
    "The `clean_text` function removes unnecessary whitespace, redundant hyphens, and formatting inconsistencies to produce clean text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the extracted text by removing extra whitespace, unnecessary hyphens, etc.\n",
    "    \"\"\"\n",
    "    cleaned_text = re.sub(r\"\\s+\", \" \", text)  # Replace multiple spaces with a single space\n",
    "    cleaned_text = cleaned_text.strip()       # Strip leading and trailing whitespace\n",
    "    cleaned_text = cleaned_text.replace(\"- \", \"\")  # Remove hyphens followed by spaces\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Create a Function to Extract Text Using Trafilatura**\n",
    "\n",
    "\n",
    "The `extract_text_trafilatura` function processes an HTML file to extract its main content and metadata using Trafilatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_trafilatura(filename):\n",
    "    \"\"\"\n",
    "    Extracts text and metadata from an HTML file using Trafilatura.\n",
    "    \"\"\"\n",
    "    json_object = {}\n",
    "    print(f\"Processing (Trafilatura): {filename}\")\n",
    "    with open(os.path.join(BASE_URI, filename), 'r', encoding='utf-8') as file:\n",
    "        try:\n",
    "            html_content = file.read()\n",
    "            result = trafilatura.extract(\n",
    "                html_content,\n",
    "                no_fallback=True,\n",
    "                include_links=False,\n",
    "                include_comments=False,\n",
    "                include_tables=False,\n",
    "                include_images=False,\n",
    "                include_formatting=True\n",
    "            )\n",
    "            metadata = trafilatura.extract_metadata(html_content)\n",
    "            json_object['title'] = metadata['title'] if metadata else None\n",
    "            json_object['main_text'] = clean_text(result) if result else None\n",
    "            json_object['filename'] = filename\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "    return json_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5: Create a Function to Extract Text Using NewsPlease**\n",
    "\n",
    "The `extract_text_newsplease` function processes an HTML file to extract structured news information using NewsPlease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_newsplease(filename):\n",
    "    \"\"\"\n",
    "    Extracts text and metadata from an HTML file using NewsPlease.\n",
    "    \"\"\"\n",
    "    json_object = {}\n",
    "    print(f\"Processing (NewsPlease): {filename}\")\n",
    "    with open(os.path.join(BASE_URI, filename), 'r', encoding='utf-8') as file:\n",
    "        try:\n",
    "            news = NewsPlease.from_html(file.read())\n",
    "            json_object['title'] = news.title\n",
    "            json_object['description'] = news.description\n",
    "            json_object['main_text'] = news.maintext\n",
    "            json_object['language'] = news.language\n",
    "            json_object['filename'] = filename\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "    return json_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 6: Process Files Using Multiprocessing**\n",
    "\n",
    "We use Python's `multiprocessing` to process multiple HTML files in parallel for efficiency. This block processes all files in the `html` folder using both `Trafilatura` and `NewsPlease`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Use a multiprocessing pool to process files in parallel\n",
    "    pool = multiprocessing.Pool(os.cpu_count())\n",
    "\n",
    "    # Extract text using Trafilatura\n",
    "    print(\"Starting Trafilatura extraction...\")\n",
    "    trafilatura_results = pool.map(extract_text_trafilatura, os.listdir(BASE_URI))\n",
    "    with open('html_json_trafilatura.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(trafilatura_results, f, ensure_ascii=False, indent=4)\n",
    "    print(\"Trafilatura extraction completed. Output saved to 'html_json_trafilatura.json'.\")\n",
    "\n",
    "    # Extract text using NewsPlease\n",
    "    print(\"Starting NewsPlease extraction...\")\n",
    "    newsplease_results = pool.map(extract_text_newsplease, os.listdir(BASE_URI))\n",
    "    with open('html_json_newsplease.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(newsplease_results, f, ensure_ascii=False, indent=4)\n",
    "    print(\"NewsPlease extraction completed. Output saved to 'html_json_newsplease.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Final Notes**\n",
    "\n",
    "This notebook demonstrates how to extract clean and structured text from HTML files using two methods. The results are saved as JSON files:\n",
    "\n",
    "1. `html_json_trafilatura.json`: Output from Trafilatura.\n",
    "2. `html_json_newsplease.json`: Output from NewsPlease.\n",
    "\n",
    "You can analyze these JSON files further for your research or application needs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
